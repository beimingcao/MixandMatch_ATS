{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyworld\n",
    "import pysptk\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nnmnkwii.preprocessing.f0 import interp1d\n",
    "from nnmnkwii.util import apply_delta_windows\n",
    "\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09ENF', '40ENF', '37ENF', '36ENF', '05ENF', '17ENF', '07ENF', '18ENF', '21ENF', '28ENF']\n"
     ]
    }
   ],
   "source": [
    "data_folder = '/home/beiming/Desktop/Parsed_data'\n",
    "group_name = 'ENF' # ENF or ENM\n",
    "group_folder = os.path.join(data_folder, group_name)\n",
    "subject_list = os.listdir(group_folder) \n",
    "print(subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_name = '09ENF'\n",
    "\n",
    "data_sub_folder = os.path.join(group_folder, sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_path_list = os.path.join(data_sub_folder, '*' + '.wav')\n",
    "WAV_path_list = glob.glob(WAV_path_list)\n",
    "WAV_path_list.sort()\n",
    "\n",
    "EMA_path_list = os.path.join(data_sub_folder, '*' + '.ema')\n",
    "EMA_path_list = glob.glob(EMA_path_list)\n",
    "EMA_path_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgc_dim = 180\n",
    "lf0_dim = 3\n",
    "vuv_dim = 1\n",
    "bap_dim = 3\n",
    "\n",
    "ema_dim = 21\n",
    "\n",
    "acoustic_dim = mgc_dim + lf0_dim + vuv_dim + bap_dim\n",
    "\n",
    "fs = 16000\n",
    "frame_period = 5\n",
    "hop_length = 80\n",
    "fftlen = 1024\n",
    "alpha = 0.41\n",
    "\n",
    "mgc_start_idx = 0\n",
    "lf0_start_idx = 180\n",
    "vuv_start_idx = 183\n",
    "bap_start_idx = 184\n",
    "\n",
    "windows = [\n",
    "    (0, 0, np.array([1.0])),\n",
    "    (1, 1, np.array([-0.5, 0.0, 0.5])),\n",
    "    (1, 1, np.array([1.0, -2.0, 1.0])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "I, fs = librosa.load(WAV_path_list[0], sr = 16000)\n",
    "\n",
    "#fs, I = wavfile.read(WAV_path_list[0])\n",
    "\n",
    "print(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld\n",
    "import pysptk\n",
    "import nnmnkwii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgc_dim = 40\n",
    "lf0_dim = 1\n",
    "vuv_dim = 1\n",
    "bap_dim = 1\n",
    "\n",
    "fs = 16000\n",
    "\n",
    "frame_period = 5\n",
    "hop_length = 80\n",
    "fftlen = 1024\n",
    "alpha = 0.41\n",
    "\n",
    "order = 39\n",
    "frame_period = 5\n",
    "windows = [\n",
    "    (0, 0, np.array([1.0])),\n",
    "    (1, 1, np.array([-0.5, 0.0, 0.5])),\n",
    "    (1, 1, np.array([1.0, -2.0, 1.0])),\n",
    "]\n",
    "\n",
    "file_num = len(WAV_path_list)\n",
    "\n",
    "train_index = range(file_num - 20)\n",
    "valid_index = range(file_num - 20, file_num - 10)\n",
    "test_index = range(file_num - 10, file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_features(wav_path, fs, frame_period, order):\n",
    "  \n",
    "    x, sr = librosa.load(wav_path, sr = fs)\n",
    "    x = x.astype(np.float64)\n",
    "    f0, timeaxis = pyworld.dio(x, fs, frame_period=frame_period)\n",
    "    f0 = pyworld.stonemask(x, f0, timeaxis, fs)\n",
    "    spectrogram = pyworld.cheaptrick(x, f0, timeaxis, fs)\n",
    "    aperiodicity = pyworld.d4c(x, f0, timeaxis, fs)\n",
    "\n",
    "    bap = pyworld.code_aperiodicity(aperiodicity, fs)\n",
    "    mgc = pysptk.sp2mc(spectrogram, order=order,\n",
    "                       alpha=pysptk.util.mcepalpha(fs))\n",
    "    f0 = f0[:, None]\n",
    "    lf0 = f0.copy()\n",
    "    nonzero_indices = np.nonzero(f0)\n",
    "    lf0[nonzero_indices] = np.log(f0[nonzero_indices])\n",
    "    vuv = (lf0 != 0).astype(np.float32)\n",
    "    lf0 = interp1d(lf0, kind=\"slinear\")\n",
    "    \n",
    "    lf0 = f0.copy()\n",
    "    nonzero_indices = np.nonzero(f0)\n",
    "    lf0[nonzero_indices] = np.log(f0[nonzero_indices])\n",
    "    vuv = (lf0 != 0).astype(np.float32)\n",
    "    lf0 = interp1d(lf0, kind=\"slinear\")\n",
    "\n",
    "    lf0 = lf0.reshape(lf0.shape[0],1)\n",
    "    vuv = vuv.reshape(vuv.shape[0],1)\n",
    "\n",
    "    mgc_delta = apply_delta_windows(mgc, windows)\n",
    "    lf0_delta = apply_delta_windows(lf0, windows)\n",
    "    bap_delta = apply_delta_windows(bap, windows)\n",
    "    \n",
    "    features = np.hstack((mgc, lf0, vuv, bap))\n",
    "\n",
    "    delta_features = np.hstack((mgc_delta, lf0_delta, vuv, bap_delta))\n",
    "    \n",
    "    return features, delta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beiming/.local/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:611: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "Valid_MV = {}\n",
    "Valid_WAV = {}\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i in valid_index:\n",
    "  \n",
    "  MV = np.loadtxt(EMA_path_list[i])\n",
    "  \n",
    "  WAV, WAV_delta = collect_features(WAV_path_list[i], fs,  frame_period, order)\n",
    "\n",
    "  scale_ratio = WAV.shape[0] / MV.shape[0]\n",
    "\n",
    "\n",
    "  MV_align = np.empty([WAV.shape[0], MV.shape[1]])\n",
    "\n",
    "  for j in range(MV.shape[1]):\n",
    "\n",
    "    MV_align[:,j] = ndimage.zoom(MV[:,j], scale_ratio)\n",
    "    \n",
    "  MV_delta = apply_delta_windows(MV_align, windows)\n",
    "  \n",
    "  \n",
    "  Valid_MV[index] = MV_delta\n",
    "  Valid_WAV[index] = WAV_delta\n",
    "  \n",
    "  index = index + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_MV = {}\n",
    "Test_WAV = {}\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i in test_index:\n",
    "  \n",
    "  MV = np.loadtxt(EMA_path_list[i])\n",
    "  \n",
    "  WAV, WAV_delta = collect_features(WAV_path_list[i], fs,  frame_period, order)\n",
    "\n",
    "  scale_ratio = WAV.shape[0] / MV.shape[0]\n",
    "\n",
    "\n",
    "  MV_align = np.empty([WAV.shape[0], MV.shape[1]])\n",
    "\n",
    "  for j in range(MV.shape[1]):\n",
    "\n",
    "    MV_align[:,j] = ndimage.zoom(MV[:,j], scale_ratio)\n",
    "    \n",
    "  MV_delta = apply_delta_windows(MV_align, windows)\n",
    "  \n",
    "  \n",
    "  Test_MV[index] = MV_delta\n",
    "  Test_WAV[index] = WAV_delta\n",
    "  \n",
    "  index = index + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_MV = {}\n",
    "Train_WAV = {}\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i in train_index:\n",
    "  \n",
    "  MV = np.loadtxt(EMA_path_list[i])\n",
    "  \n",
    "  WAV, WAV_delta = collect_features(WAV_path_list[i], fs,  frame_period, order)\n",
    "\n",
    "  scale_ratio = WAV.shape[0] / MV.shape[0]\n",
    "\n",
    "\n",
    "  MV_align = np.empty([WAV.shape[0], MV.shape[1]])\n",
    "\n",
    "  for j in range(MV.shape[1]):\n",
    "\n",
    "    MV_align[:,j] = ndimage.zoom(MV[:,j], scale_ratio)\n",
    "    \n",
    "  MV_delta = apply_delta_windows(MV_align, windows)\n",
    "  \n",
    "  \n",
    "  Train_MV[index] = MV_delta\n",
    "  Train_WAV[index] = WAV_delta\n",
    "  \n",
    "  index = index + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125649, 63)\n",
      "(125649, 127)\n",
      "(9192, 63)\n",
      "(9192, 127)\n",
      "(6813, 63)\n",
      "(6813, 127)\n",
      "[[-3.3395802e+01  1.6143700e+01  7.9419999e+00 ...  4.9904375e+00\n",
      "   6.8988562e+00  1.6429406e-01]\n",
      " [-3.3483120e+01  1.5874749e+01  7.8733754e+00 ...  2.6739890e-02\n",
      "   5.0346792e-02 -1.2042025e-01]\n",
      " [-3.3419582e+01  1.5773069e+01  7.8436131e+00 ...  1.7501785e-01\n",
      "   1.6871114e-01  1.6737479e-01]\n",
      " ...\n",
      " [-3.6329300e+01  1.3279700e+01  8.4714003e+00 ... -7.9999998e-02\n",
      "   8.3800003e-02 -1.0800000e-02]\n",
      " [-3.6477600e+01  1.3283700e+01  8.4361000e+00 ... -9.3999997e-02\n",
      "  -5.1000002e-03  2.8200001e-02]\n",
      " [-3.6623501e+01  1.3301900e+01  8.4468002e+00 ...  5.8501000e+00\n",
      "   7.4232998e+00  1.7875000e+00]]\n",
      "[[-7.62988842e+00  1.14834979e+00  9.78014884e-01 ... -8.68569749e-12\n",
      "  -4.34284875e-12  8.68569749e-12]\n",
      " [-7.43905389e+00  9.52134296e-01  7.73554656e-01 ... -8.68569749e-12\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-7.49806685e+00  8.37806475e-01  4.51986261e-01 ... -8.68569749e-12\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [-6.38372230e+00  7.69321935e-01 -1.32007393e-01 ... -8.68569749e-12\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-6.52886552e+00  7.87444523e-01 -1.47366864e-01 ... -8.68569749e-12\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-6.56244728e+00  6.55245250e-01  1.82762124e-01 ... -8.68569749e-12\n",
      "   4.34284875e-12  8.68569749e-12]]\n"
     ]
    }
   ],
   "source": [
    "Train_MV_block = np.concatenate([Train_MV[x] for x in Train_MV], 0).astype(np.float32)\n",
    "Train_WAV_block = np.concatenate([Train_WAV[x] for x in Train_WAV], 0)\n",
    "\n",
    "Valid_MV_block = np.concatenate([Valid_MV[x] for x in Valid_MV], 0).astype(np.float32)\n",
    "Valid_WAV_block = np.concatenate([Valid_WAV[x] for x in Valid_WAV], 0)\n",
    "\n",
    "Test_MV_block = np.concatenate([Test_MV[x] for x in Test_MV], 0).astype(np.float32)\n",
    "Test_WAV_block = np.concatenate([Test_WAV[x] for x in Test_WAV], 0)\n",
    "\n",
    "print(Train_MV_block.shape)\n",
    "print(Train_WAV_block.shape)\n",
    "\n",
    "print(Valid_MV_block.shape)\n",
    "print(Valid_WAV_block.shape)\n",
    "\n",
    "print(Test_MV_block.shape)\n",
    "print(Test_WAV_block.shape)\n",
    "\n",
    "print(Train_MV_block)\n",
    "print(Train_WAV_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tnrange, tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils import data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    \"\"\"Very simple deep neural networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, D_in, H, D_out, num_layers=2):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.first_linear = nn.Linear(D_in, H)\n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [nn.Linear(H, H) for _ in range(num_layers)])\n",
    "        self.last_linear = nn.Linear(H, D_out)\n",
    "        self.relu = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.first_linear(x))\n",
    "        for hl in self.hidden_layers:\n",
    "            h = self.relu(hl(h))\n",
    "        return self.last_linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 3\n",
    "hidden_size = 256\n",
    "batch_size = 1024\n",
    "# We use PyTorch's multiprocess iterator. Note that large n_workers causes\n",
    "# dataset copies across proccess.\n",
    "n_workers = 4\n",
    "pin_memory = True\n",
    "nepoch = 25\n",
    "lr = 0.001\n",
    "weight_decay = 1e-6\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_tensor_MV = torch.from_numpy(Train_MV_block)\n",
    "Train_tensor_MV = Train_tensor_MV.float()\n",
    "\n",
    "Train_tensor_WAV = torch.from_numpy(Train_WAV_block)\n",
    "Train_tensor_WAV = Train_tensor_WAV.float()\n",
    "\n",
    "Valid_tensor_MV = torch.from_numpy(Valid_MV_block)\n",
    "Valid_tensor_MV = Valid_tensor_MV.float()\n",
    "\n",
    "Valid_tensor_WAV = torch.from_numpy(Valid_WAV_block)\n",
    "Valid_tensor_WAV = Valid_tensor_WAV.float()\n",
    "\n",
    "Train_loader = data_utils.TensorDataset(Train_tensor_MV, Train_tensor_WAV)\n",
    "Train_loader_dataset = data_utils.DataLoader(Train_loader, batch_size=batch_size, num_workers=n_workers, pin_memory=pin_memory,shuffle = False)\n",
    "\n",
    "Valid_loader = data_utils.TensorDataset(Valid_tensor_MV, Valid_tensor_WAV)\n",
    "Valid_loader_dataset = data_utils.DataLoader(Valid_loader, batch_size=batch_size, num_workers=n_workers, pin_memory=pin_memory,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MyNet(\n",
      "  (first_linear): Linear(in_features=63, out_features=256, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=256, out_features=127, bias=True)\n",
      "  (relu): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNet(Train_MV_block.shape[1], hidden_size, Train_WAV_block.shape[1], num_hidden_layers)\n",
    "print(\"Model\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start frame-wise training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f407f222bc64e10990914a92262f5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: nan\n",
      "Validation loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-48093f56e684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model.train()\n",
    "print(\"Start frame-wise training...\")\n",
    "loss_history = {\"Train\": [], \"Valid\": []}\n",
    "\n",
    "dataset_loaders = {\"Train\": Train_loader_dataset, \"Valid\": Valid_loader_dataset}\n",
    "    \n",
    "for epoch in tnrange(nepoch):\n",
    "    ## training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in Train_loader:\n",
    "       # if use_cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        x, y = Variable(x), Variable(y)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    loss_history[\"Train\"].append(running_loss / len(dataset_loaders[\"Train\"]))\n",
    "    print(\"Training loss:\", running_loss)\n",
    "\n",
    "    ## validating\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    for x, y in Valid_loader:\n",
    " #       if use_cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        x, y = Variable(x), Variable(y)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y) \n",
    "        running_loss += loss.item()\n",
    "    loss_history[\"Valid\"].append(running_loss / len(dataset_loaders[\"Valid\"]))\n",
    "    \n",
    "    print(\"Validation loss:\", running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_history[\"Train\"], linewidth=2, label=\"Train loss\")\n",
    "plot(loss_history[\"Valid\"], linewidth=2, label=\"Test loss\")\n",
    "legend(prop={\"size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
